{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pytorch 2.0.1\n",
      "cuda is available False\n"
     ]
    }
   ],
   "source": [
    "print('hello pytorch {}'.format(torch.__version__))\n",
    "print('cuda is available {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.autograd.Variable:\n",
    "\n",
    "data:被包装的Tensor\n",
    "\n",
    "grad:data的梯度\n",
    "\n",
    "grad_fn:创建Tensor的Function 是自动求导的关键\n",
    "\n",
    "requires_grad:指示是否需要梯度\n",
    "\n",
    "is_leaf:指示是否是叶子结点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch 0.4.0之后 Variable并入Tensor\n",
    "\n",
    "torch.Tensor:\n",
    "\n",
    "dtype:\n",
    "\n",
    "张量的数据类型 如torch.FloatTensor,torch.cuda.FloatTensor     \n",
    "\n",
    "用的最多的是torch.float32  卷积层的权值 图像预处理之后\n",
    "\n",
    "torch.long/int64 图像标签\n",
    "\n",
    "shape:张量的形状，如(64，3，224，224)\n",
    "\n",
    "device:张量所在设备 GPU/CPU\n",
    "\n",
    "同上\n",
    "data  grad  grad_fn  requires_grad  is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.直接创建 \n",
    "\n",
    "1.1torch.tensor() 从data创建tensor 参数如下：\n",
    "\n",
    "data: list/numpy\n",
    "\n",
    "dtype: 默认与data一致\n",
    "\n",
    "device：cuda/cpu\n",
    "\n",
    "requires_grad: 是否需要梯度\n",
    "\n",
    "pin_memory:是否存于锁业内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "arr = np.ones((3,3))\n",
    "print(arr.dtype)\n",
    "t = torch.tensor(arr)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 torch.from_numpy(ndarray) 从numpy创建tensor\n",
    "\n",
    "注意：torch.from_numpy创建的tensor与原numpy共享内存 修改其中一个 另一个也随之改动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]] tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "[[-1  2  3]\n",
      " [ 4  5  6]] tensor([[-1,  2,  3],\n",
      "        [ 4,  5,  6]], dtype=torch.int32)\n",
      "[[-1  2  3]\n",
      " [ 4  8  6]] tensor([[-1,  2,  3],\n",
      "        [ 4,  8,  6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "t = torch.from_numpy(arr)\n",
    "print(arr,t)\n",
    "t[0,0] = -1\n",
    "print(arr,t)\n",
    "arr[1,1] = 8\n",
    "print(arr,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.依据数值创建\n",
    "\n",
    "2.1 torch.zeros() 根据size创建全0张量 参数如下：\n",
    "\n",
    "size:张量形状 如(3,224,224)\n",
    "\n",
    "out:输出的张量\n",
    "\n",
    "layout:内存中布局形式\n",
    "\n",
    "device and  requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "1683530510112 1683530510112 True\n"
     ]
    }
   ],
   "source": [
    "out_t = torch.tensor([1])\n",
    "print(out_t)\n",
    "t = torch.zeros((3,3),out=out_t)\n",
    "print(t)\n",
    "print(out_t)\n",
    "print(id(t),id(out_t),id(t)==id(out_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 torch.zeros_like() torch.ones_like()根据input形状创建全0/1张量 params：\n",
    "\n",
    "input:创建与input同形状的全0张量\n",
    "\n",
    "dtype and layout and device and requires_grad\n",
    "\n",
    "类似还有torch.full() torch.full_like() params:\n",
    "\n",
    "size fill_value:填充的张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 3, 3],\n",
       "         [3, 3, 3],\n",
       "         [3, 3, 3]]),\n",
       " tensor([[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [1, 1, 1]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.full((3,3),fill_value=3)\n",
    "x = torch.full((3,3),fill_value=1)\n",
    "t,x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.arange() 创建等差的1维张量 数值区间为[start,end) params:\n",
    "\n",
    "start:起始值(包含)\n",
    "\n",
    "end:结束值(不包含)\n",
    "\n",
    "step：数列公差，默认为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(2,10,2)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.linspace() 创建均分的1维张量 数值区间为[start,end]\n",
    "\n",
    "start:起始值(包含)\n",
    "\n",
    "end:结束值(不包含)\n",
    "\n",
    "steps：数列长度\n",
    "\n",
    "步长step为 (end-start)/(steps-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.,  4.,  6.,  8., 10.]),\n",
       " tensor([ 2.0000,  3.3333,  4.6667,  6.0000,  7.3333,  8.6667, 10.0000]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.linspace(2,10,5)\n",
    "t2 = torch.linspace(2,10,7)\n",
    "t1,t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.logspace() 创建对数均分的1维张量 params：\n",
    "\n",
    "start end steps base：对数函数的底 默认为10\n",
    "\n",
    "torch.eye() 创建单位对角矩阵（2维张量 默认方阵 params：\n",
    "\n",
    "n:行数 m:列数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.依概率分布创建张量\n",
    "\n",
    "3.1 torch.normal() 生成正态分布(高斯分布) params：\n",
    "\n",
    "mean:均值  std:方差\n",
    "\n",
    "四种模式\n",
    "\n",
    "mean为标量  std为标量\n",
    "\n",
    "mean为标量  std为张量\n",
    "\n",
    "mean为张量  std为标量\n",
    "\n",
    "mean为张量  std为张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.]) tensor([1., 2., 3., 4.])\n",
      "tensor([1.6680, 1.9197, 2.6898, 5.1459])\n"
     ]
    }
   ],
   "source": [
    "#mean为张量  std为张量\n",
    "mean = torch.arange(1,5,dtype=torch.float)\n",
    "std = torch.arange(1,5,dtype=torch.float)\n",
    "t_normal = torch.normal(mean,std)\n",
    "print(mean,std)\n",
    "print(t_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面 1.6680 是通过mean=1 std=1的分布采样的来的\n",
    "\n",
    "而5.1459是通过mean=5 std=5的分布采样得来的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8605,  0.7200,  0.1049, -0.5543])\n"
     ]
    }
   ],
   "source": [
    "#mean为标量  std为标量\n",
    "t_normal = torch.normal(0,1,size=(4,))\n",
    "print(t_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.]) 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.1520, 1.5583, 3.1499, 3.3331])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean为张量  std为标量\n",
    "#均值不一样 方差相同\n",
    "mean = torch.arange(1,5,dtype=torch.float)\n",
    "std = 1\n",
    "t_normal = torch.normal(mean,std)\n",
    "print(mean,std)\n",
    "t_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([1., 2., 3., 4.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.7448,  1.2380,  0.7298,  7.3911])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean为标量  std为标量\n",
    "#方差不一样 均值相同\n",
    "std = torch.arange(1,5,dtype=torch.float)\n",
    "mean = 0\n",
    "t_normal = torch.normal(mean,std)\n",
    "print(mean,std)\n",
    "t_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 torch.randn()  生成标准正态分布 params:\n",
    "\n",
    "size: 张量的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.rand()\n",
    "\n",
    "torch.rand_like()\n",
    "\n",
    "[0,1)上的均匀分布\n",
    "\n",
    "torch.randint()\n",
    "\n",
    "torch.randint_like()\n",
    "\n",
    "区间[low,high)生成整数均匀分布 params： size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.randperm() 生成从0到n-1的随机排列 params: \n",
    " \n",
    "n:张量的长度\n",
    "\n",
    "torch.bernoulli() 以input为概率 生成伯努利分布（0-1分布/两点分布） params：\n",
    "\n",
    "input:概率值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
